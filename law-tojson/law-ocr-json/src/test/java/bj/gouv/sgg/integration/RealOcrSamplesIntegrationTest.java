package bj.gouv.sgg.integration;

import bj.gouv.sgg.config.ArticleExtractorConfig;
import bj.gouv.sgg.impl.ArticleRegexExtractor;
import bj.gouv.sgg.impl.CsvCorrector;
import bj.gouv.sgg.model.Article;
import bj.gouv.sgg.model.DocumentMetadata;
import bj.gouv.sgg.service.OcrExtractionService;
import lombok.extern.slf4j.Slf4j;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.List;
import java.util.stream.Stream;

import static org.junit.jupiter.api.Assertions.*;

/**
 * Tests d'int√©gration sur les vrais √©chantillons OCR du dossier samples_ocr/
 * 
 * Ces tests valident que le pipeline complet (correction ‚Üí extraction) 
 * fonctionne sur des documents r√©els avec erreurs OCR typiques.
 */
@Slf4j
class RealOcrSamplesIntegrationTest {
    
    private ArticleExtractorConfig config;
    private CsvCorrector corrector;
    private OcrExtractionService extractionService;
    
    private Path samplesPath;
    
    @BeforeEach
    void setUp() {
        // Initialisation manuelle des composants
        config = new ArticleExtractorConfig();
        config.init(); // Appel manuel de @PostConstruct
        
        corrector = new CsvCorrector();
        extractionService = new ArticleRegexExtractor(config);
        
        samplesPath = Paths.get("src/test/resources/samples_ocr");
        assertTrue(Files.exists(samplesPath), "Le dossier samples_ocr doit exister");
    }
    
    @Test
    void givenRealOcrSampleLoi2024_1WhenApplyFullPipelineThenExtractsArticlesSuccessfully() throws IOException {
        // Document r√©cent avec erreurs OCR typiques
        Path loiPath = samplesPath.resolve("loi/loi-2024-1.txt");
        String rawOcr = Files.readString(loiPath);
        
        // √âtape 1 : Correction
        String corrected = corrector.applyCorrections(rawOcr);
        assertNotNull(corrected);
        assertFalse(corrected.isEmpty());
        
        // √âtape 2 : Extraction articles
        List<Article> articles = extractionService.extractArticles(corrected);
        assertNotNull(articles);
        assertTrue(articles.size() >= 1, "loi-2024-1 devrait contenir au moins 1 article");
        log.info("‚úÖ loi-2024-1 : {} articles extraits", articles.size());
        
        // √âtape 3 : M√©tadonn√©es
        DocumentMetadata metadata = extractionService.extractMetadata(corrected);
        assertNotNull(metadata);
        
        // √âtape 4 : Confiance
        double confidence = extractionService.calculateConfidence(corrected, articles);
        assertTrue(confidence >= 0.0 && confidence <= 1.0);
        log.info("‚úÖ loi-2024-1 : confiance = {}", confidence);
    }
    
    @Test
    void givenRealOcrSampleLoi2020_1WhenApplyFullPipelineThenExtractsArticlesSuccessfully() throws IOException {
        // Document avec structure claire et signataires
        Path loiPath = samplesPath.resolve("loi/loi-2020-1.txt");
        String rawOcr = Files.readString(loiPath);
        
        // V√©rifier pr√©sence texte cl√©
        assertTrue(rawOcr.contains("R√âPUBLIQUE") || rawOcr.contains("R√âPUBLIaUE"));
        assertTrue(rawOcr.contains("ASSEMBL√âE") || rawOcr.contains("ASSE√ÄABL√âE"));
        
        String corrected = corrector.applyCorrections(rawOcr);
        List<Article> articles = extractionService.extractArticles(corrected);
        
        assertNotNull(articles);
        assertTrue(articles.size() >= 1, "loi-2020-1 devrait contenir au moins 1 article");
        
        // V√©rifier contenu article
        Article firstArticle = articles.get(0);
        assertNotNull(firstArticle.getContent());
        assertFalse(firstArticle.getContent().trim().isEmpty());
        
        log.info("‚úÖ loi-2020-1 : {} articles, premier article {} chars", 
                 articles.size(), firstArticle.getContent().length());
        
        // M√©tadonn√©es
        DocumentMetadata metadata = extractionService.extractMetadata(corrected);
        assertNotNull(metadata);
        
        // V√©rifier extraction date (04 f√©vrier 2020)
        if (metadata.getPromulgationDate() != null) {
            log.info("Date extraite : {}", metadata.getPromulgationDate());
        }
        
        // V√©rifier extraction ville (Cotonou)
        if (metadata.getPromulgationCity() != null) {
            log.info("Ville extraite : {}", metadata.getPromulgationCity());
        }
    }
    
    @Test
    void testDecret2024_1632_FullPipeline() throws IOException {
        // D√©cret avec structure complexe (chapitres, sections)
        Path decretPath = samplesPath.resolve("decret/decret-2024-1632.txt");
        String rawOcr = Files.readString(decretPath);
        
        String corrected = corrector.applyCorrections(rawOcr);
        List<Article> articles = extractionService.extractArticles(corrected);
        
        assertNotNull(articles);
        assertTrue(articles.size() >= 1, "decret-2024-1632 devrait contenir des articles");
        log.info("‚úÖ decret-2024-1632 : {} articles extraits", articles.size());
        
        // V√©rifier num√©rotation articles
        for (Article article : articles) {
            assertTrue(article.getIndex() > 0, "Index article devrait √™tre positif");
            assertNotNull(article.getContent());
        }
        
        // M√©tadonn√©es
        DocumentMetadata metadata = extractionService.extractMetadata(corrected);
        assertNotNull(metadata);
        
        double confidence = extractionService.calculateConfidence(corrected, articles);
        assertTrue(confidence > 0.0, "Confiance devrait √™tre > 0");
        log.info("‚úÖ decret-2024-1632 : confiance = {}", confidence);
    }
    
    @Test
    void testLoi1991_10_OldDocument() throws IOException {
        // Document ancien (1991) avec OCR de mauvaise qualit√©
        Path loiPath = samplesPath.resolve("loi/loi-1991-10.txt");
        String rawOcr = Files.readString(loiPath);
        
        String corrected = corrector.applyCorrections(rawOcr);
        
        // Sur document ancien, on accepte qu'il y ait peu d'articles extraits
        try {
            List<Article> articles = extractionService.extractArticles(corrected);
            assertNotNull(articles);
            log.info("‚úÖ loi-1991-10 : {} articles extraits (document ancien)", articles.size());
            
            DocumentMetadata metadata = extractionService.extractMetadata(corrected);
            assertNotNull(metadata);
            
        } catch (Exception e) {
            // OK si √©chec sur document tr√®s ancien avec OCR d√©grad√©
            log.warn("‚ö†Ô∏è loi-1991-10 : extraction difficile (document ancien) : {}", e.getMessage());
        }
    }
    
    @Test
    void testMultipleSamples_Statistics() throws IOException {
        // Test statistique sur plusieurs √©chantillons
        int totalFiles = 0;
        int successfulExtractions = 0;
        int totalArticles = 0;
        
        // Tester tous les fichiers loi/
        try (Stream<Path> paths = Files.walk(samplesPath.resolve("loi"))) {
            List<Path> loiFiles = paths
                .filter(Files::isRegularFile)
                .filter(p -> p.toString().endsWith(".txt"))
                .limit(10) // Limiter √† 10 fichiers pour performance
                .toList();
            
            for (Path loiFile : loiFiles) {
                totalFiles++;
                try {
                    String rawOcr = Files.readString(loiFile);
                    String corrected = corrector.applyCorrections(rawOcr);
                    List<Article> articles = extractionService.extractArticles(corrected);
                    
                    if (!articles.isEmpty()) {
                        successfulExtractions++;
                        totalArticles += articles.size();
                        log.debug("‚úÖ {} : {} articles", loiFile.getFileName(), articles.size());
                    }
                } catch (Exception e) {
                    log.debug("‚ö†Ô∏è {} : √©chec extraction : {}", loiFile.getFileName(), e.getMessage());
                }
            }
        }
        
        log.info("üìä Statistiques : {}/{} fichiers trait√©s avec succ√®s", successfulExtractions, totalFiles);
        log.info("üìä Total articles extraits : {}", totalArticles);
        log.info("üìä Moyenne : {} articles/document", totalFiles > 0 ? totalArticles / (double) totalFiles : 0);
        
        assertTrue(totalFiles > 0, "Devrait avoir test√© au moins 1 fichier");
        assertTrue(successfulExtractions >= totalFiles / 2, 
                   "Au moins 50% des fichiers devraient √™tre extraits avec succ√®s");
    }
    
    @Test
    void testCorrectionQuality_BeforeAfter() throws IOException {
        // V√©rifier que les corrections am√©liorent la qualit√©
        Path loiPath = samplesPath.resolve("loi/loi-2024-1.txt");
        String rawOcr = Files.readString(loiPath);
        
        // Qualit√© avant correction
        double unrecBefore = config.unrecognizedWordsRate(rawOcr);
        
        // Correction
        String corrected = corrector.applyCorrections(rawOcr);
        
        // Qualit√© apr√®s correction
        double unrecAfter = config.unrecognizedWordsRate(corrected);
        
        log.info("üìä Qualit√© OCR : avant={}, apr√®s={}", unrecBefore, unrecAfter);
        
        // La correction devrait am√©liorer ou maintenir la qualit√©
        assertTrue(unrecAfter <= unrecBefore + 0.05, 
                   "Les corrections ne devraient pas d√©grader la qualit√©");
    }
    
    @Test
    void testArticleExtractionConsistency() throws IOException {
        // V√©rifier que l'extraction est coh√©rente (m√™me document ‚Üí m√™me r√©sultat)
        Path loiPath = samplesPath.resolve("loi/loi-2020-1.txt");
        String rawOcr = Files.readString(loiPath);
        String corrected = corrector.applyCorrections(rawOcr);
        
        // Premi√®re extraction
        List<Article> articles1 = extractionService.extractArticles(corrected);
        
        // Deuxi√®me extraction (m√™me texte)
        List<Article> articles2 = extractionService.extractArticles(corrected);
        
        // R√©sultats identiques
        assertEquals(articles1.size(), articles2.size(), 
                     "L'extraction devrait √™tre d√©terministe");
        
        for (int i = 0; i < articles1.size(); i++) {
            assertEquals(articles1.get(i).getIndex(), articles2.get(i).getIndex());
            assertEquals(articles1.get(i).getContent(), articles2.get(i).getContent());
        }
        
        log.info("‚úÖ Extraction coh√©rente : {} articles", articles1.size());
    }
    
    @Test
    void testMetadataExtraction_MultipleDocuments() throws IOException {
        // Tester extraction m√©tadonn√©es sur plusieurs documents
        List<String> testFiles = List.of(
            "loi/loi-2024-1.txt",
            "loi/loi-2020-1.txt",
            "decret/decret-2024-1632.txt"
        );
        
        int documentsWithDate = 0;
        int documentsWithCity = 0;
        int documentsWithTitle = 0;
        
        for (String testFile : testFiles) {
            Path filePath = samplesPath.resolve(testFile);
            if (!Files.exists(filePath)) continue;
            
            String rawOcr = Files.readString(filePath);
            String corrected = corrector.applyCorrections(rawOcr);
            DocumentMetadata metadata = extractionService.extractMetadata(corrected);
            
            assertNotNull(metadata, "Metadata ne devrait jamais √™tre null");
            
            if (metadata.getPromulgationDate() != null) documentsWithDate++;
            if (metadata.getPromulgationCity() != null) documentsWithCity++;
            if (metadata.getLawTitle() != null) documentsWithTitle++;
            
            log.debug("üìÑ {} : date={}, ville={}, titre={}", 
                     testFile, 
                     metadata.getPromulgationDate() != null,
                     metadata.getPromulgationCity() != null,
                     metadata.getLawTitle() != null);
        }
        
        log.info("üìä M√©tadonn√©es extraites : dates={}, villes={}, titres={}", 
                 documentsWithDate, documentsWithCity, documentsWithTitle);
    }
}
